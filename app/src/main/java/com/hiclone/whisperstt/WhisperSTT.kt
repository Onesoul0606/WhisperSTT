package com.hiclone.whisperstt

import android.content.Context
import android.util.Log
import java.io.File
import java.io.FileOutputStream
import java.io.IOException
import kotlinx.coroutines.*

class WhisperSTT {

    companion object {
        private const val TAG = "WhisperSTT"
        private var libraryLoaded = false

        init {
            try {
                System.loadLibrary("whisperstt")
                libraryLoaded = true
                Log.d(TAG, "Native library loaded successfully")
            } catch (e: UnsatisfiedLinkError) {
                Log.e(TAG, "Failed to load native library", e)
                libraryLoaded = false
            } catch (e: Exception) {
                Log.e(TAG, "Unexpected error loading native library", e)
                libraryLoaded = false
            }
        }
    }

    // Native ë©”ì†Œë“œë“¤ (Step 1ì—ì„œ ì¶”ê°€í•œ JNI ë©”ì„œë“œë“¤)
    private external fun loadModel(modelPath: String): Boolean
    private external fun transcribe(audioData: FloatArray): String
    private external fun transcribeWithPrompt(audioData: FloatArray, prompt: String): String // âœ¨ ìƒˆë¡œ ì¶”ê°€
    private external fun transcribeRealtime(audioData: FloatArray): String // âœ¨ ìƒˆë¡œ ì¶”ê°€
    private external fun releaseModel()
    private external fun isModelLoaded(): Boolean

    // ì‹¤ì‹œê°„ STTìš© ë³€ìˆ˜ë“¤
    private var audioCapture: AudioCapture? = null
    private var streamingProcessor: Any? = null  // í”„ë¡œì„¸ì„œ íƒ€ìž…ì€ ë‚˜ì¤‘ì— ì„¤ì •
    private var onRealtimeResult: ((String) -> Unit)? = null
    private var onStatusChanged: ((String) -> Unit)? = null
    private var scope = CoroutineScope(Dispatchers.IO + SupervisorJob())
    
    // ì „ì—­ ì¤‘ì§€ ìƒíƒœ ê´€ë¦¬
    @Volatile
    private var isSTTStopped = false

    /**
     * ë„¤ì´í‹°ë¸Œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ìƒíƒœ í™•ì¸
     */
    fun isNativeLibraryLoaded(): Boolean {
        return libraryLoaded
    }

    /**
     * Assetsì—ì„œ ëª¨ë¸ íŒŒì¼ì„ ë‚´ë¶€ ì €ìž¥ì†Œë¡œ ë³µì‚¬í•˜ê³  ë¡œë“œ
     */
    fun loadModelFromAssets(context: Context, assetFileName: String): Boolean {
        if (!libraryLoaded) {
            Log.e(TAG, "Native library not loaded, cannot load model")
            return false
        }

        return try {
            // assets í´ë” ë‚´ìš© í™•ì¸ (ë””ë²„ê¹…ìš©)
            val assetManager = context.assets
            Log.d(TAG, "Checking assets folder contents...")

            try {
                val rootFiles = assetManager.list("")
                Log.d(TAG, "Root assets: ${rootFiles?.joinToString(", ")}")

                val modelsFiles = assetManager.list("models")
                Log.d(TAG, "Models folder: ${modelsFiles?.joinToString(", ")}")
            } catch (e: Exception) {
                Log.e(TAG, "Failed to list assets", e)
            }

            // assetFileNameì´ "models/ggml-tiny.en.bin" í˜•íƒœì¸ì§€ í™•ì¸
            val actualAssetPath = if (assetFileName.startsWith("models/")) {
                assetFileName
            } else {
                "models/$assetFileName"
            }
            
            val modelFile = copyAssetToFile(context, actualAssetPath)
            val result = loadModel(modelFile.absolutePath)
            Log.d(TAG, "Model loading result: $result")
            result
        } catch (e: Exception) {
            Log.e(TAG, "Failed to load model from assets", e)
            false
        }
    }

    /**
     * ì§ì ‘ íŒŒì¼ ê²½ë¡œë¡œ ëª¨ë¸ ë¡œë“œ
     */
    fun loadModelFromPath(modelPath: String): Boolean {
        if (!libraryLoaded) {
            Log.e(TAG, "Native library not loaded, cannot load model")
            return false
        }

        val file = File(modelPath)
        if (!file.exists()) {
            Log.e(TAG, "Model file does not exist: $modelPath")
            return false
        }

        val result = loadModel(modelPath)
        Log.d(TAG, "Model loading result: $result")
        return result
    }

    /**
     * ì˜¤ë””ì˜¤ ë°ì´í„° ìŒì„± ì¸ì‹ (ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰)
     */
    fun transcribeAudio(audioData: FloatArray, callback: (String) -> Unit) {
        // ì¤‘ì§€ ìƒíƒœ í™•ì¸
        if (isSTTStopped) {
            Log.d(TAG, "STT is stopped, ignoring transcription request")
            return
        }
        
        if (!libraryLoaded) {
            Log.e(TAG, "Native library not loaded, cannot transcribe")
            callback("ERROR: Native library not loaded")
            return
        }

        if (!isModelLoaded()) {
            Log.w(TAG, "Model not loaded, cannot transcribe")
            callback("ERROR: Model not loaded")
            return
        }

        Log.d(TAG, "Starting transcription with ${audioData.size} samples")

        // ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ìŒì„± ì¸ì‹ ì‹¤í–‰
        scope.launch {
            try {
                // ë‹¤ì‹œ í•œ ë²ˆ ì¤‘ì§€ ìƒíƒœ í™•ì¸
                if (isSTTStopped) {
                    Log.d(TAG, "STT stopped during transcription, aborting")
                    return@launch
                }
                
                val startTime = System.currentTimeMillis()
                val result = transcribe(audioData)
                val endTime = System.currentTimeMillis()

                // ê²°ê³¼ ì½œë°± ì „ì—ë„ ì¤‘ì§€ ìƒíƒœ í™•ì¸
                if (!isSTTStopped) {
                    Log.d(TAG, "Transcription completed in ${endTime - startTime}ms")
                    callback(result)
                } else {
                    Log.d(TAG, "STT stopped, ignoring transcription result")
                }
            } catch (e: Exception) {
                if (!isSTTStopped) {
                    Log.e(TAG, "Error during transcription", e)
                    callback("ERROR: Transcription failed - ${e.message}")
                }
            }
        }
    }

    /**
     * ë™ê¸°ì‹ ìŒì„± ì¸ì‹ (ê¸°ì¡´ ë©”ì†Œë“œ ìœ ì§€)
     */
    fun transcribeAudioSync(audioData: FloatArray): String {
        // ì¤‘ì§€ ìƒíƒœ í™•ì¸
        if (isSTTStopped) {
            Log.d(TAG, "STT is stopped, ignoring sync transcription request")
            return ""
        }
        
        if (!libraryLoaded) {
            Log.e(TAG, "Native library not loaded, cannot transcribe")
            return "ERROR: Native library not loaded"
        }

        if (!isModelLoaded()) {
            Log.w(TAG, "Model not loaded, cannot transcribe")
            return "ERROR: Model not loaded"
        }

        Log.d(TAG, "Transcribing audio with ${audioData.size} samples")
        val startTime = System.currentTimeMillis()

        return try {
            // ì²˜ë¦¬ ì „ì—ë„ ì¤‘ì§€ ìƒíƒœ í™•ì¸
            if (isSTTStopped) {
                Log.d(TAG, "STT stopped during sync transcription, aborting")
                return ""
            }
            
            val result = transcribe(audioData)

            // ê²°ê³¼ ë°˜í™˜ ì „ì—ë„ ì¤‘ì§€ ìƒíƒœ í™•ì¸
            if (isSTTStopped) {
                Log.d(TAG, "STT stopped, ignoring sync transcription result")
                return ""
            }

            val endTime = System.currentTimeMillis()
            Log.d(TAG, "Transcription completed in ${endTime - startTime}ms")
            result
        } catch (e: Exception) {
            if (!isSTTStopped) {
                Log.e(TAG, "Error in sync transcription", e)
                "ERROR: Transcription failed - ${e.message}"
            } else {
                ""
            }
        }
    }

    /**
     * Short ë°°ì—´ìš© ë™ê¸°ì‹ ìŒì„± ì¸ì‹ (ì‹¤ì‹œê°„ STTìš©)
     */
    fun transcribeAudioSync(audioData: ShortArray): String {
        if (!libraryLoaded) {
            Log.e(TAG, "Native library not loaded, cannot transcribe")
            return ""
        }

        if (!isModelLoaded()) {
            Log.w(TAG, "Model not loaded, cannot transcribe")
            return ""
        }

        return try {
            // Short ë°°ì—´ì„ Float ë°°ì—´ë¡œ ë³€í™˜ (ì •ê·œí™”)
            val floatData = audioData.map { it.toFloat() / Short.MAX_VALUE }.toFloatArray()
            transcribeAudioSync(floatData)
        } catch (e: Exception) {
            Log.e(TAG, "Error converting short array to float array", e)
            ""
        }
    }

    /**
     * ë…¼ë¬¸ êµ¬í˜„ì„ ìœ„í•œ Context Prompt ì§€ì› ìŒì„± ì¸ì‹
     * Whisper Streaming ë…¼ë¬¸ì˜ 200ìž ì œí•œ prompt ì‚¬ìš©
     */
    fun transcribeWithContext(audioData: ShortArray, context: String): String {
        if (!libraryLoaded) {
            Log.e(TAG, "Native library not loaded, cannot transcribe")
            return ""
        }

        if (!isModelLoaded()) {
            Log.w(TAG, "Model not loaded, cannot transcribe")
            return ""
        }

        return try {
            // Short ë°°ì—´ì„ Float ë°°ì—´ë¡œ ë³€í™˜
            val floatData = audioData.map { it.toFloat() / Short.MAX_VALUE }.toFloatArray()
            
            if (context.isNotEmpty()) {
                // ë…¼ë¬¸ì˜ 200ìž ì œí•œ ì ìš©
                val limitedPrompt = if (context.length > 200) {
                    context.takeLast(200)
                } else {
                    context
                }
                Log.d(TAG, "Transcribing with prompt (${limitedPrompt.length} chars): '${limitedPrompt.take(50)}${if (limitedPrompt.length > 50) "..." else ""}'")
                transcribeWithPrompt(floatData, limitedPrompt)
            } else {
                transcribe(floatData)
            }
        } catch (e: Exception) {
            Log.e(TAG, "Error in transcription with context", e)
            // Fallback to regular transcription
            try {
                transcribeAudioSync(audioData)
            } catch (fallbackE: Exception) {
                Log.e(TAG, "Fallback transcription also failed", fallbackE)
                "ERROR: ${e.message}"
            }
        }
    }
    
    /**
     * FloatArrayìš© Context ì§€ì› ìŒì„± ì¸ì‹
     */
    fun transcribeWithContext(audioData: FloatArray, context: String): String {
        if (!libraryLoaded) {
            Log.e(TAG, "Native library not loaded, cannot transcribe")
            return ""
        }

        if (!isModelLoaded()) {
            Log.w(TAG, "Model not loaded, cannot transcribe")
            return ""
        }

        return try {
            if (context.isNotEmpty()) {
                // ë…¼ë¬¸ì˜ 200ìž ì œí•œ ì ìš©
                val limitedPrompt = if (context.length > 200) {
                    context.takeLast(200)
                } else {
                    context
                }
                transcribeWithPrompt(audioData, limitedPrompt)
            } else {
                transcribe(audioData)
            }
        } catch (e: Exception) {
            Log.e(TAG, "Error in transcription with context", e)
            // Fallback to regular transcription
            try {
                transcribe(audioData)
            } catch (fallbackE: Exception) {
                Log.e(TAG, "Fallback transcription also failed", fallbackE)
                "ERROR: ${e.message}"
            }
        }
    }

    /**
     * âœ¨ ì‹¤ì‹œê°„ ìµœì í™”ëœ ì „ì‚¬ (Step 2 ì¶”ê°€)
     */
    fun transcribeRealtimeOptimized(audioData: ShortArray): String {
        if (!libraryLoaded) {
            Log.e(TAG, "Native library not loaded, cannot transcribe")
            return ""
        }

        if (!isModelLoaded()) {
            Log.w(TAG, "Model not loaded, cannot transcribe")
            return ""
        }

        return try {
            // Short ë°°ì—´ì„ Float ë°°ì—´ë¡œ ë³€í™˜
            val floatData = audioData.map { it.toFloat() / Short.MAX_VALUE }.toFloatArray()
            
            transcribeRealtime(floatData)
        } catch (e: Exception) {
            Log.e(TAG, "Error in realtime transcription", e)
            // Fallback to regular transcription
            transcribeAudioSync(audioData)
        }
    }

    /**
     * âœ¨ í”„ë¡œì„¸ì„œ íƒ€ìž… ì„ íƒ ê°€ëŠ¥í•œ ì‹¤ì‹œê°„ STT ì‹œìž‘ (Step 2 ê°œì„ )
     */
    fun startRealtimeSTT(
        onResult: (String) -> Unit,
        onStatus: (String) -> Unit,
        processorType: StreamingProcessorType = StreamingProcessorType.WHISPER_STREAMING
    ): Boolean {
        if (!libraryLoaded) {
            Log.e(TAG, "Cannot start realtime STT: Native library not loaded")
            onStatus("ë„¤ì´í‹°ë¸Œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return false
        }

        if (!isModelLoaded()) {
            Log.e(TAG, "Cannot start realtime STT: Model not loaded")
            onStatus("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return false
        }

        if (audioCapture?.isRecording() == true) {
            Log.w(TAG, "Realtime STT already running")
            return true
        }

        // STT ì‹œìž‘ - ì¤‘ì§€ ìƒíƒœ í•´ì œ
        isSTTStopped = false
        
        onRealtimeResult = onResult
        onStatusChanged = onStatus

        // AudioCapture ì´ˆê¸°í™”
        audioCapture = AudioCapture()

        // ì„ íƒëœ í”„ë¡œì„¸ì„œ íƒ€ìž…ì— ë”°ë¼ ì´ˆê¸°í™”
        streamingProcessor = when (processorType) {
            StreamingProcessorType.SLIDING_WINDOW -> {
                SlidingWindowProcessor(this) { result ->
                    if (!isSTTStopped) {
                        onRealtimeResult?.invoke("ðŸ”„ $result")
                    }
                }
            }
            StreamingProcessorType.WHISPER_STREAMING -> {
                ImprovedWhisperStreamingProcessor(this) { text, isFinal ->
                    if (!isSTTStopped) {
                        if (isFinal) {
                            onRealtimeResult?.invoke("âœ… $text")
                        } else {
                            onRealtimeResult?.invoke("âš¡ $text")
                        }
                    }
                }
            }
        }

        // ì˜¤ë””ì˜¤ ë°ì´í„° ì½œë°± ì„¤ì •
        audioCapture?.setAudioDataCallback { audioData ->
            try {
                when (val processor = streamingProcessor) {
                    is ImprovedWhisperStreamingProcessor -> processor.addAudioData(audioData)
                }
            } catch (e: Exception) {
                Log.e(TAG, "Error in audio data callback", e)
            }
        }
        
        // ShortArray ì½œë°± ì„¤ì • (SlidingWindowProcessorìš©)
        audioCapture?.setShortAudioDataCallback { shortAudioData ->
            try {
                when (val processor = streamingProcessor) {
                    is SlidingWindowProcessor -> processor.addAudioData(shortAudioData)
                }
            } catch (e: Exception) {
                Log.e(TAG, "Error in short audio data callback", e)
            }
        }

        // í”„ë¡œì„¸ì„œ ì‹œìž‘
        when (val processor = streamingProcessor) {
            is SlidingWindowProcessor -> processor.start()
            is ImprovedWhisperStreamingProcessor -> processor.start()
        }

        // ì˜¤ë””ì˜¤ ë…¹ìŒ ì‹œìž‘
        val recordingStarted = audioCapture?.startRecording() ?: false
        if (recordingStarted) {
            onStatusChanged?.invoke("Realtime STT started with ${processorType.displayName}")
            Log.i(TAG, "Realtime STT started with ${processorType.displayName}")
            return true
        } else {
            Log.e(TAG, "Failed to start audio recording")
            onStatusChanged?.invoke("ì˜¤ë””ì˜¤ ë…¹ìŒì„ ì‹œìž‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return false
        }
    }

    /**
     * ì‹¤ì‹œê°„ STT ì¤‘ì§€
     */
    fun stopRealtimeSTT() {
        try {
            Log.i(TAG, "Stopping realtime STT...")
            
            // 0. ì¦‰ì‹œ ì¤‘ì§€ ìƒíƒœ ì„¤ì • (ê°€ìž¥ ë¨¼ì €!)
            isSTTStopped = true
            
            // 1. ë¨¼ì € í”„ë¡œì„¸ì„œ ì¤‘ì§€ (ìƒˆë¡œìš´ ë°ì´í„° ì²˜ë¦¬ ì¤‘ë‹¨)
            when (val processor = streamingProcessor) {
                is SlidingWindowProcessor -> processor.stop()
                is ImprovedWhisperStreamingProcessor -> processor.stop()
            }
            
            // 2. ì˜¤ë””ì˜¤ ë…¹ìŒ ì¤‘ì§€
            audioCapture?.stopRecording()
            
            // 3. ëª¨ë“  ì‹¤í–‰ ì¤‘ì¸ ì½”ë£¨í‹´ ì·¨ì†Œí•˜ê³  ìƒˆ ìŠ¤ì½”í”„ ìƒì„±
            scope.cancel()
            scope = CoroutineScope(Dispatchers.IO + SupervisorJob())
            
            // 4. ì½œë°± í•´ì œ (ê²°ê³¼ ë¬´ì‹œ)
            onRealtimeResult = null
            onStatusChanged = null
            
            // 5. ë¦¬ì†ŒìŠ¤ í•´ì œ
            audioCapture?.release()
            audioCapture = null
            streamingProcessor = null
            
            Log.i(TAG, "All callbacks and resources cleared")
            Log.i(TAG, "Realtime STT stopped successfully")
        } catch (e: Exception) {
            Log.e(TAG, "Error stopping realtime STT", e)
            // ê°•ì œë¡œ ìƒíƒœ ì´ˆê¸°í™”
            isSTTStopped = true
            audioCapture = null
            streamingProcessor = null
        }
    }

    /**
     * ì‹¤ì‹œê°„ STT ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
     */
    fun isRealtimeSTTRunning(): Boolean {
        return audioCapture?.isRecording() == true
    }

    /**
     * ëª¨ë¸ ë¡œë“œ ìƒíƒœ í™•ì¸
     */
    fun isLoaded(): Boolean {
        return libraryLoaded && isModelLoaded()
    }

    /**
     * STT ì¤‘ì§€ ìƒíƒœ í™•ì¸ (í”„ë¡œì„¸ì„œì—ì„œ ì‚¬ìš©)
     */
    fun isSTTStopped(): Boolean {
        return isSTTStopped
    }

    /**
     * ë¦¬ì†ŒìŠ¤ í•´ì œ
     */
    fun release() {
        try {
            stopRealtimeSTT()
            if (libraryLoaded) {
                releaseModel()
            }
            scope.cancel()
        } catch (e: Exception) {
            Log.e(TAG, "Error releasing resources", e)
        }
    }

    /**
     * Assets íŒŒì¼ì„ ë‚´ë¶€ ì €ìž¥ì†Œë¡œ ë³µì‚¬
     */
    private fun copyAssetToFile(context: Context, assetFileName: String): File {
        // assetFileNameì—ì„œ íŒŒì¼ëª…ë§Œ ì¶”ì¶œ (ê²½ë¡œ ì œê±°)
        val fileName = File(assetFileName).name
        
        val modelDir = File(context.filesDir, "models")
        if (!modelDir.exists()) {
            modelDir.mkdirs()
        }

        val modelFile = File(modelDir, fileName)
        
        if (!modelFile.exists()) {
            try {
                context.assets.open(assetFileName).use { input ->
                    FileOutputStream(modelFile).use { output ->
                        input.copyTo(output)
                    }
                }
                Log.d(TAG, "Model file copied to: ${modelFile.absolutePath}")
            } catch (e: IOException) {
                Log.e(TAG, "Failed to copy model file", e)
                throw e
            }
        }

        return modelFile
    }
}

